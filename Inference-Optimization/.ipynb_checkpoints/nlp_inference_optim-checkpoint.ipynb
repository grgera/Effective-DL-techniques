{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers Inference Optimization for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look on three things that can be done after training to improve inference speed:\n",
    "* [TorchScript](https://pytorch.org/docs/stable/jit.html)\n",
    "* [Dynamic Quantization](https://pytorch.org/docs/stable/quantization.html)\n",
    "* [ONNX](https://pytorch.org/docs/stable/onnx.html) and [ONNX Runntime](https://github.com/microsoft/onnxruntime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchScript is a way to create serializable and optimizable models from PyTorch code. The models can be run independently from Python environment, such as C++.\n",
    "\n",
    "To trace our model, we must define model input first. \n",
    "\n",
    "*Note: For GPU inference we must change device to 'cuda'.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541da97fc1ee4fc59a4cb2576d151678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85368a92c25e4cbeb5a67aa91dc60a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "def sentence_input(sentence: str, max_len: int = 512, device = 'cpu'):\n",
    "    encoded = tokenizer.encode_plus(sentence, add_special_tokens=True, \n",
    "                                    pad_to_max_length=True, max_length=max_len, \n",
    "                                    return_tensors=\"pt\",).to(device)\n",
    "    model_input = (encoded['input_ids'], encoded['attention_mask'])\n",
    "    return model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"Super Cute: First of all, I LOVE this product. When I bought it my husband jokingly said that it looked cute and small in the picture, but was really HUGE in real life. Don't tell him I said so, but he was right. It is huge and the cord is really long. Although I wish it was smaller, I still love it. It works really well when we travel and need to plug a lot of things in and although the length is annoying, it's very useful.\"\n",
    "model_input = sentence_input(test_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting model - CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class DistilBert(nn.Module):\n",
    "    def __init__(self, pretrained_model_name: str, num_classes: int = None):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(\n",
    "             pretrained_model_name)\n",
    "\n",
    "        self.distilbert = AutoModel.from_pretrained(pretrained_model_name,\n",
    "                                                    config=config)\n",
    "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
    "        self.classifier = nn.Linear(config.dim, num_classes)\n",
    "        self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
    "\n",
    "    def forward(self, features, attention_mask=None, head_mask=None):\n",
    "\n",
    "        assert attention_mask is not None, \"attention mask is none\"\n",
    "        distilbert_output = self.distilbert(input_ids=features,\n",
    "                                            attention_mask=attention_mask,\n",
    "                                            head_mask=head_mask)\n",
    "\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n",
    "\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
    "        pooled_output = self.pre_classifier(pooled_output)  # (bs, dim)\n",
    "        pooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\n",
    "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
    "        logits = self.classifier(pooled_output)  # (bs, dim)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041bc4ffcd0448ce956f837800f6e201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "model = DistilBert(pretrained_model_name=MODEL_NAME,\n",
    "                                           num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from catalyst.dl.utils import trace\n",
    "def load_chechpoint(model, path):\n",
    "    mod = trace.load_checkpoint(path)\n",
    "    model.load_state_dict(mod['model_state_dict'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_chechpoint(model, '../input/sentiment-all-models/last 0.9622.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "traced_cpu = torch.jit.trace(model, model_input)\n",
    "torch.jit.save(traced_cpu, \"cpu.pth\")\n",
    "\n",
    "#to load\n",
    "cpu_model = torch.jit.load(\"cpu.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.DistilBert,\n",
      "      %input_ids.1 : Tensor,\n",
      "      %argument_2.1 : Tensor):\n",
      "  %15 : int = prim::Constant[value=0]() # <ipython-input-9-d0a4bb00ec17>:49:0\n",
      "  %16 : int = prim::Constant[value=9223372036854775807]() # <ipython-input-9-d0a4bb00ec17>:49:0\n",
      "  %17 : int = prim::Constant[value=1]() # <ipython-input-9-d0a4bb00ec17>:49:0\n",
      "  %4 : __torch__.torch.nn.modules.linear.___torch_mangle_82.Linear = prim::GetAttr[name=\"classifier\"](%self.1)\n",
      "  %6 : __torch__.torch.nn.modules.dropout.___torch_mangle_83.Dropout = prim::GetAttr[name=\"dropout\"](%self.1)\n",
      "  %8 : __torch__.torch.nn.modules.linear.___torch_mangle_81.Linear = prim::GetAttr[name=\"pre_classifier\"](%self.1)\n",
      "  %10 : __torch__.transformers.modeling_distilbert.DistilBertModel = prim::GetAttr[name=\"distilbert\"](%self.1)\n",
      "  %13 : Tensor = prim::CallMethod[name=\"forward\"](%10, %input_ids.1, %argument_2.1) # :0:0\n",
      "  %18 : Tensor = aten::slice(%13, %15, %15, %16, %17) # <ipython-input-9-d0a4bb00ec17>:49:0\n",
      "  %input.1 : Tensor = aten::select(%18, %17, %15) # <ipython-input-9-d0a4bb00ec17>:49:0\n",
      "  %23 : Tensor = prim::CallMethod[name=\"forward\"](%8, %input.1) # :0:0\n",
      "  %input0.1 : Tensor = aten::relu(%23) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1063:0\n",
      "  %28 : Tensor = prim::CallMethod[name=\"forward\"](%6, %input0.1) # :0:0\n",
      "  %29 : Tensor = prim::CallMethod[name=\"forward\"](%4, %28) # :0:0\n",
      "  return (%29)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cpu_model.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post Training Dynamic Quantization: This is the form of quantization where the weights are quantized ahead of time but the activations are dynamically quantized during inference.\n",
    "\n",
    "Dynamic quantization support in PyTorch converts a float model to a quantized model with static int8 or float16 data types for the weights and dynamic quantization for the activations. The activations are quantized dynamically (per batch) to int8 when the weights are quantized to int8.\n",
    "\n",
    "The mapping is performed by converting the floating point tensors using:\n",
    "\n",
    "![](https://pytorch.org/docs/stable/_images/math-quantizer-equation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBert(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, qscheme=torch.per_tensor_affine)\n",
      "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, qscheme=torch.per_tensor_affine)\n",
      "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, qscheme=torch.per_tensor_affine)\n",
      "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, qscheme=torch.per_tensor_affine)\n",
      "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, qscheme=torch.per_tensor_affine)\n",
      "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (k_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (v_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "            (out_lin): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): DynamicQuantizedLinear(in_features=768, out_features=3072, qscheme=torch.per_tensor_affine)\n",
      "            (lin2): DynamicQuantizedLinear(in_features=3072, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): DynamicQuantizedLinear(in_features=768, out_features=768, qscheme=torch.per_tensor_affine)\n",
      "  (classifier): DynamicQuantizedLinear(in_features=768, out_features=2, qscheme=torch.per_tensor_affine)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model size decreased from 255 to 132 MB. If we calculate the total size of word embedding table ~ 4 (Bytes/FP32) * 30522(Vocabulary Size) * 768(Embedding Size) = 90 MB. Then the model size reduced from 165 to 42MB (INT8 Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONNX provides an open source format for AI models, both deep learning and traditional ML. It defines an extensible computation graph model, as well as definitions of built-in operators and standard data types.\n",
    "\n",
    "ONNX Runtime is a performance-focused engine(written in C++) for ONNX models, which inferences efficiently across multiple platforms and hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_ids : Long(1, 512),\n",
      "      %attention_mask : Long(1, 512),\n",
      "      %distilbert.embeddings.word_embeddings.weight : Float(30522, 768),\n",
      "      %distilbert.embeddings.position_embeddings.weight : Float(512, 768),\n",
      "      %distilbert.embeddings.LayerNorm.weight : Float(768),\n",
      "      %distilbert.embeddings.LayerNorm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.0.attention.q_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.0.attention.k_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.0.attention.v_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.0.attention.out_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.0.sa_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.0.sa_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.0.ffn.lin1.bias : Float(3072),\n",
      "      %distilbert.transformer.layer.0.ffn.lin2.bias : Float(768),\n",
      "      %distilbert.transformer.layer.0.output_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.0.output_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.1.attention.q_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.1.attention.k_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.1.attention.v_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.1.attention.out_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.1.sa_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.1.sa_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.1.ffn.lin1.bias : Float(3072),\n",
      "      %distilbert.transformer.layer.1.ffn.lin2.bias : Float(768),\n",
      "      %distilbert.transformer.layer.1.output_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.1.output_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.2.attention.q_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.2.attention.k_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.2.attention.v_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.2.attention.out_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.2.sa_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.2.sa_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.2.ffn.lin1.bias : Float(3072),\n",
      "      %distilbert.transformer.layer.2.ffn.lin2.bias : Float(768),\n",
      "      %distilbert.transformer.layer.2.output_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.2.output_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.3.attention.q_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.3.attention.k_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.3.attention.v_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.3.attention.out_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.3.sa_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.3.sa_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.3.ffn.lin1.bias : Float(3072),\n",
      "      %distilbert.transformer.layer.3.ffn.lin2.bias : Float(768),\n",
      "      %distilbert.transformer.layer.3.output_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.3.output_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.4.attention.q_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.4.attention.k_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.4.attention.v_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.4.attention.out_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.4.sa_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.4.sa_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.4.ffn.lin1.bias : Float(3072),\n",
      "      %distilbert.transformer.layer.4.ffn.lin2.bias : Float(768),\n",
      "      %distilbert.transformer.layer.4.output_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.4.output_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.5.attention.q_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.5.attention.k_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.5.attention.v_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.5.attention.out_lin.bias : Float(768),\n",
      "      %distilbert.transformer.layer.5.sa_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.5.sa_layer_norm.bias : Float(768),\n",
      "      %distilbert.transformer.layer.5.ffn.lin1.bias : Float(3072),\n",
      "      %distilbert.transformer.layer.5.ffn.lin2.bias : Float(768),\n",
      "      %distilbert.transformer.layer.5.output_layer_norm.weight : Float(768),\n",
      "      %distilbert.transformer.layer.5.output_layer_norm.bias : Float(768),\n",
      "      %pre_classifier.weight : Float(768, 768),\n",
      "      %pre_classifier.bias : Float(768),\n",
      "      %classifier.weight : Float(2, 768),\n",
      "      %classifier.bias : Float(2),\n",
      "      %821 : Float(768, 768),\n",
      "      %822 : Long(1),\n",
      "      %823 : Long(1),\n",
      "      %824 : Long(1),\n",
      "      %825 : Float(768, 768),\n",
      "      %826 : Long(1),\n",
      "      %827 : Long(1),\n",
      "      %828 : Long(1),\n",
      "      %829 : Float(768, 768),\n",
      "      %830 : Long(1),\n",
      "      %831 : Long(1),\n",
      "      %832 : Long(1),\n",
      "      %833 : Long(1),\n",
      "      %834 : Long(1),\n",
      "      %835 : Long(1),\n",
      "      %836 : Long(1),\n",
      "      %837 : Float(768, 768),\n",
      "      %838 : Float(768, 3072),\n",
      "      %839 : Float(3072, 768),\n",
      "      %840 : Float(768, 768),\n",
      "      %841 : Long(1),\n",
      "      %842 : Long(1),\n",
      "      %843 : Long(1),\n",
      "      %844 : Float(768, 768),\n",
      "      %845 : Long(1),\n",
      "      %846 : Long(1),\n",
      "      %847 : Long(1),\n",
      "      %848 : Float(768, 768),\n",
      "      %849 : Long(1),\n",
      "      %850 : Long(1),\n",
      "      %851 : Long(1),\n",
      "      %852 : Long(1),\n",
      "      %853 : Long(1),\n",
      "      %854 : Long(1),\n",
      "      %855 : Long(1),\n",
      "      %856 : Float(768, 768),\n",
      "      %857 : Float(768, 3072),\n",
      "      %858 : Float(3072, 768),\n",
      "      %859 : Float(768, 768),\n",
      "      %860 : Long(1),\n",
      "      %861 : Long(1),\n",
      "      %862 : Long(1),\n",
      "      %863 : Float(768, 768),\n",
      "      %864 : Long(1),\n",
      "      %865 : Long(1),\n",
      "      %866 : Long(1),\n",
      "      %867 : Float(768, 768),\n",
      "      %868 : Long(1),\n",
      "      %869 : Long(1),\n",
      "      %870 : Long(1),\n",
      "      %871 : Long(1),\n",
      "      %872 : Long(1),\n",
      "      %873 : Long(1),\n",
      "      %874 : Long(1),\n",
      "      %875 : Float(768, 768),\n",
      "      %876 : Float(768, 3072),\n",
      "      %877 : Float(3072, 768),\n",
      "      %878 : Float(768, 768),\n",
      "      %879 : Long(1),\n",
      "      %880 : Long(1),\n",
      "      %881 : Long(1),\n",
      "      %882 : Float(768, 768),\n",
      "      %883 : Long(1),\n",
      "      %884 : Long(1),\n",
      "      %885 : Long(1),\n",
      "      %886 : Float(768, 768),\n",
      "      %887 : Long(1),\n",
      "      %888 : Long(1),\n",
      "      %889 : Long(1),\n",
      "      %890 : Long(1),\n",
      "      %891 : Long(1),\n",
      "      %892 : Long(1),\n",
      "      %893 : Long(1),\n",
      "      %894 : Float(768, 768),\n",
      "      %895 : Float(768, 3072),\n",
      "      %896 : Float(3072, 768),\n",
      "      %897 : Float(768, 768),\n",
      "      %898 : Long(1),\n",
      "      %899 : Long(1),\n",
      "      %900 : Long(1),\n",
      "      %901 : Float(768, 768),\n",
      "      %902 : Long(1),\n",
      "      %903 : Long(1),\n",
      "      %904 : Long(1),\n",
      "      %905 : Float(768, 768),\n",
      "      %906 : Long(1),\n",
      "      %907 : Long(1),\n",
      "      %908 : Long(1),\n",
      "      %909 : Long(1),\n",
      "      %910 : Long(1),\n",
      "      %911 : Long(1),\n",
      "      %912 : Long(1),\n",
      "      %913 : Float(768, 768),\n",
      "      %914 : Float(768, 3072),\n",
      "      %915 : Float(3072, 768),\n",
      "      %916 : Float(768, 768),\n",
      "      %917 : Long(1),\n",
      "      %918 : Long(1),\n",
      "      %919 : Long(1),\n",
      "      %920 : Float(768, 768),\n",
      "      %921 : Long(1),\n",
      "      %922 : Long(1),\n",
      "      %923 : Long(1),\n",
      "      %924 : Float(768, 768),\n",
      "      %925 : Long(1),\n",
      "      %926 : Long(1),\n",
      "      %927 : Long(1),\n",
      "      %928 : Long(1),\n",
      "      %929 : Long(1),\n",
      "      %930 : Long(1),\n",
      "      %931 : Long(1),\n",
      "      %932 : Float(768, 768),\n",
      "      %933 : Float(768, 3072),\n",
      "      %934 : Float(3072, 768)):\n",
      "  %106 : Tensor = onnx::Shape(%input_ids)\n",
      "  %107 : Tensor = onnx::Constant[value={1}]()\n",
      "  %108 : Long() = onnx::Gather[axis=0](%106, %107) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:87:0\n",
      "  %109 : Tensor = onnx::Unsqueeze[axes=[0]](%108)\n",
      "  %110 : Tensor = onnx::ConstantOfShape[value={1}](%109)\n",
      "  %111 : Tensor = onnx::NonZero(%110)\n",
      "  %112 : Tensor = onnx::Transpose[perm=[1, 0]](%111)\n",
      "  %113 : Tensor = onnx::Squeeze[axes=[1]](%112)\n",
      "  %114 : Long(512) = onnx::Cast[to=7](%113) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:88:0\n",
      "  %115 : Long(1, 512) = onnx::Unsqueeze[axes=[0]](%114) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:89:0\n",
      "  %116 : Tensor = onnx::Shape(%input_ids)\n",
      "  %117 : Long(1, 512) = onnx::Expand(%115, %116) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:89:0\n",
      "  %118 : Float(1, 512, 768) = onnx::Gather(%distilbert.embeddings.word_embeddings.weight, %input_ids) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1724:0\n",
      "  %119 : Float(1, 512, 768) = onnx::Gather(%distilbert.embeddings.position_embeddings.weight, %117) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1724:0\n",
      "  %120 : Float(1, 512, 768) = onnx::Add(%118, %119) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:94:0\n",
      "  %121 : Tensor = onnx::ReduceMean[axes=[-1]](%120)\n",
      "  %122 : FloatTensor = onnx::Sub(%120, %121)\n",
      "  %123 : Float() = onnx::Constant[value={2}]()\n",
      "  %124 : FloatTensor = onnx::Pow(%122, %123)\n",
      "  %125 : Tensor = onnx::ReduceMean[axes=[-1]](%124)\n",
      "  %126 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %127 : FloatTensor = onnx::Add(%125, %126)\n",
      "  %128 : Tensor = onnx::Sqrt(%127)\n",
      "  %129 : FloatTensor = onnx::Div(%122, %128)\n",
      "  %130 : FloatTensor = onnx::Mul(%129, %distilbert.embeddings.LayerNorm.weight)\n",
      "  %131 : Float(1, 512, 768) = onnx::Add(%130, %distilbert.embeddings.LayerNorm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %132 : Tensor = onnx::Shape(%131)\n",
      "  %133 : Tensor = onnx::Constant[value={0}]()\n",
      "  %134 : Long() = onnx::Gather[axis=0](%132, %133) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:155:0\n",
      "  %135 : Tensor = onnx::Shape(%131)\n",
      "  %136 : Tensor = onnx::Constant[value={1}]()\n",
      "  %137 : Long() = onnx::Gather[axis=0](%135, %136) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:156:0\n",
      "  %139 : Float(1, 512, 768) = onnx::MatMul(%131, %821) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %140 : Float(1, 512, 768) = onnx::Add(%139, %distilbert.transformer.layer.0.attention.q_lin.bias)\n",
      "  %144 : Tensor = onnx::Unsqueeze[axes=[0]](%134)\n",
      "  %148 : Tensor = onnx::Concat[axis=0](%144, %822, %823, %824)\n",
      "  %149 : Float(1, 512, 12, 64) = onnx::Reshape(%140, %148) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %150 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%149) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %152 : Float(1, 512, 768) = onnx::MatMul(%131, %825) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %153 : Float(1, 512, 768) = onnx::Add(%152, %distilbert.transformer.layer.0.attention.k_lin.bias)\n",
      "  %157 : Tensor = onnx::Unsqueeze[axes=[0]](%134)\n",
      "  %161 : Tensor = onnx::Concat[axis=0](%157, %826, %827, %828)\n",
      "  %162 : Float(1, 512, 12, 64) = onnx::Reshape(%153, %161) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %164 : Float(1, 512, 768) = onnx::MatMul(%131, %829) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %165 : Float(1, 512, 768) = onnx::Add(%164, %distilbert.transformer.layer.0.attention.v_lin.bias)\n",
      "  %169 : Tensor = onnx::Unsqueeze[axes=[0]](%134)\n",
      "  %173 : Tensor = onnx::Concat[axis=0](%169, %830, %831, %832)\n",
      "  %174 : Float(1, 512, 12, 64) = onnx::Reshape(%165, %173) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %175 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%174) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %176 : Float() = onnx::Constant[value={8}]()\n",
      "  %177 : Float(1, 12, 512, 64) = onnx::Div(%150, %176)\n",
      "  %178 : Float(1, 12, 64, 512) = onnx::Transpose[perm=[0, 2, 3, 1]](%162) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %179 : Float(1, 12, 512, 512) = onnx::MatMul(%177, %178) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %180 : Long() = onnx::Constant[value={0}]()\n",
      "  %181 : Bool(1, 512) = onnx::Equal(%attention_mask, %180) # /opt/conda/lib/python3.7/site-packages/torch/tensor.py:28:0\n",
      "  %184 : Tensor = onnx::Unsqueeze[axes=[0]](%134)\n",
      "  %187 : Tensor = onnx::Unsqueeze[axes=[0]](%137)\n",
      "  %188 : Tensor = onnx::Concat[axis=0](%184, %833, %834, %187)\n",
      "  %189 : Bool(1, 1, 1, 512) = onnx::Reshape(%181, %188) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %190 : Tensor = onnx::Shape(%179)\n",
      "  %191 : Bool(1, 12, 512, 512) = onnx::Expand(%189, %190) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %192 : Tensor = onnx::Cast[to=9](%191)\n",
      "  %193 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %194 : Float(1, 12, 512, 512) = onnx::Where(%192, %193, %179) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:179:0\n",
      "  %195 : Float(1, 12, 512, 512) = onnx::Softmax[axis=3](%194) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %196 : Float(1, 12, 512, 64) = onnx::MatMul(%195, %175) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:188:0\n",
      "  %197 : Float(1, 512, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%196) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %200 : Tensor = onnx::Unsqueeze[axes=[0]](%134)\n",
      "  %203 : Tensor = onnx::Concat[axis=0](%200, %835, %836)\n",
      "  %204 : Float(1, 512, 768) = onnx::Reshape(%197, %203) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %206 : Float(1, 512, 768) = onnx::MatMul(%204, %837) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %207 : Float(1, 512, 768) = onnx::Add(%206, %distilbert.transformer.layer.0.attention.out_lin.bias)\n",
      "  %208 : Float(1, 512, 768) = onnx::Add(%207, %131) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:252:0\n",
      "  %209 : Tensor = onnx::ReduceMean[axes=[-1]](%208)\n",
      "  %210 : FloatTensor = onnx::Sub(%208, %209)\n",
      "  %211 : Float() = onnx::Constant[value={2}]()\n",
      "  %212 : FloatTensor = onnx::Pow(%210, %211)\n",
      "  %213 : Tensor = onnx::ReduceMean[axes=[-1]](%212)\n",
      "  %214 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %215 : FloatTensor = onnx::Add(%213, %214)\n",
      "  %216 : Tensor = onnx::Sqrt(%215)\n",
      "  %217 : FloatTensor = onnx::Div(%210, %216)\n",
      "  %218 : FloatTensor = onnx::Mul(%217, %distilbert.transformer.layer.0.sa_layer_norm.weight)\n",
      "  %219 : Float(1, 512, 768) = onnx::Add(%218, %distilbert.transformer.layer.0.sa_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %221 : Float(1, 512, 3072) = onnx::MatMul(%219, %838) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %222 : Float(1, 512, 3072) = onnx::Add(%221, %distilbert.transformer.layer.0.ffn.lin1.bias)\n",
      "  %223 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %224 : FloatTensor = onnx::Div(%222, %223)\n",
      "  %225 : Tensor = onnx::Erf(%224)\n",
      "  %226 : Float() = onnx::Constant[value={1}]()\n",
      "  %227 : FloatTensor = onnx::Add(%225, %226)\n",
      "  %228 : FloatTensor = onnx::Mul(%222, %227)\n",
      "  %229 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %230 : Float(1, 512, 3072) = onnx::Mul(%228, %229) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1313:0\n",
      "  %232 : Float(1, 512, 768) = onnx::MatMul(%230, %839) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %233 : Float(1, 512, 768) = onnx::Add(%232, %distilbert.transformer.layer.0.ffn.lin2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %234 : Float(1, 512, 768) = onnx::Add(%233, %219) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:256:0\n",
      "  %235 : Tensor = onnx::ReduceMean[axes=[-1]](%234)\n",
      "  %236 : FloatTensor = onnx::Sub(%234, %235)\n",
      "  %237 : Float() = onnx::Constant[value={2}]()\n",
      "  %238 : FloatTensor = onnx::Pow(%236, %237)\n",
      "  %239 : Tensor = onnx::ReduceMean[axes=[-1]](%238)\n",
      "  %240 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %241 : FloatTensor = onnx::Add(%239, %240)\n",
      "  %242 : Tensor = onnx::Sqrt(%241)\n",
      "  %243 : FloatTensor = onnx::Div(%236, %242)\n",
      "  %244 : FloatTensor = onnx::Mul(%243, %distilbert.transformer.layer.0.output_layer_norm.weight)\n",
      "  %245 : Float(1, 512, 768) = onnx::Add(%244, %distilbert.transformer.layer.0.output_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %246 : Tensor = onnx::Shape(%245)\n",
      "  %247 : Tensor = onnx::Constant[value={0}]()\n",
      "  %248 : Long() = onnx::Gather[axis=0](%246, %247) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:155:0\n",
      "  %249 : Tensor = onnx::Shape(%245)\n",
      "  %250 : Tensor = onnx::Constant[value={1}]()\n",
      "  %251 : Long() = onnx::Gather[axis=0](%249, %250) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:156:0\n",
      "  %253 : Float(1, 512, 768) = onnx::MatMul(%245, %840) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %254 : Float(1, 512, 768) = onnx::Add(%253, %distilbert.transformer.layer.1.attention.q_lin.bias)\n",
      "  %258 : Tensor = onnx::Unsqueeze[axes=[0]](%248)\n",
      "  %262 : Tensor = onnx::Concat[axis=0](%258, %841, %842, %843)\n",
      "  %263 : Float(1, 512, 12, 64) = onnx::Reshape(%254, %262) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %264 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%263) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %266 : Float(1, 512, 768) = onnx::MatMul(%245, %844) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %267 : Float(1, 512, 768) = onnx::Add(%266, %distilbert.transformer.layer.1.attention.k_lin.bias)\n",
      "  %271 : Tensor = onnx::Unsqueeze[axes=[0]](%248)\n",
      "  %275 : Tensor = onnx::Concat[axis=0](%271, %845, %846, %847)\n",
      "  %276 : Float(1, 512, 12, 64) = onnx::Reshape(%267, %275) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %278 : Float(1, 512, 768) = onnx::MatMul(%245, %848) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %279 : Float(1, 512, 768) = onnx::Add(%278, %distilbert.transformer.layer.1.attention.v_lin.bias)\n",
      "  %283 : Tensor = onnx::Unsqueeze[axes=[0]](%248)\n",
      "  %287 : Tensor = onnx::Concat[axis=0](%283, %849, %850, %851)\n",
      "  %288 : Float(1, 512, 12, 64) = onnx::Reshape(%279, %287) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %289 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%288) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %290 : Float() = onnx::Constant[value={8}]()\n",
      "  %291 : Float(1, 12, 512, 64) = onnx::Div(%264, %290)\n",
      "  %292 : Float(1, 12, 64, 512) = onnx::Transpose[perm=[0, 2, 3, 1]](%276) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %293 : Float(1, 12, 512, 512) = onnx::MatMul(%291, %292) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %294 : Long() = onnx::Constant[value={0}]()\n",
      "  %295 : Bool(1, 512) = onnx::Equal(%attention_mask, %294) # /opt/conda/lib/python3.7/site-packages/torch/tensor.py:28:0\n",
      "  %298 : Tensor = onnx::Unsqueeze[axes=[0]](%248)\n",
      "  %301 : Tensor = onnx::Unsqueeze[axes=[0]](%251)\n",
      "  %302 : Tensor = onnx::Concat[axis=0](%298, %852, %853, %301)\n",
      "  %303 : Bool(1, 1, 1, 512) = onnx::Reshape(%295, %302) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %304 : Tensor = onnx::Shape(%293)\n",
      "  %305 : Bool(1, 12, 512, 512) = onnx::Expand(%303, %304) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %306 : Tensor = onnx::Cast[to=9](%305)\n",
      "  %307 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %308 : Float(1, 12, 512, 512) = onnx::Where(%306, %307, %293) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:179:0\n",
      "  %309 : Float(1, 12, 512, 512) = onnx::Softmax[axis=3](%308) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %310 : Float(1, 12, 512, 64) = onnx::MatMul(%309, %289) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:188:0\n",
      "  %311 : Float(1, 512, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%310) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %314 : Tensor = onnx::Unsqueeze[axes=[0]](%248)\n",
      "  %317 : Tensor = onnx::Concat[axis=0](%314, %854, %855)\n",
      "  %318 : Float(1, 512, 768) = onnx::Reshape(%311, %317) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %320 : Float(1, 512, 768) = onnx::MatMul(%318, %856) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %321 : Float(1, 512, 768) = onnx::Add(%320, %distilbert.transformer.layer.1.attention.out_lin.bias)\n",
      "  %322 : Float(1, 512, 768) = onnx::Add(%321, %245) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:252:0\n",
      "  %323 : Tensor = onnx::ReduceMean[axes=[-1]](%322)\n",
      "  %324 : FloatTensor = onnx::Sub(%322, %323)\n",
      "  %325 : Float() = onnx::Constant[value={2}]()\n",
      "  %326 : FloatTensor = onnx::Pow(%324, %325)\n",
      "  %327 : Tensor = onnx::ReduceMean[axes=[-1]](%326)\n",
      "  %328 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %329 : FloatTensor = onnx::Add(%327, %328)\n",
      "  %330 : Tensor = onnx::Sqrt(%329)\n",
      "  %331 : FloatTensor = onnx::Div(%324, %330)\n",
      "  %332 : FloatTensor = onnx::Mul(%331, %distilbert.transformer.layer.1.sa_layer_norm.weight)\n",
      "  %333 : Float(1, 512, 768) = onnx::Add(%332, %distilbert.transformer.layer.1.sa_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %335 : Float(1, 512, 3072) = onnx::MatMul(%333, %857) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %336 : Float(1, 512, 3072) = onnx::Add(%335, %distilbert.transformer.layer.1.ffn.lin1.bias)\n",
      "  %337 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %338 : FloatTensor = onnx::Div(%336, %337)\n",
      "  %339 : Tensor = onnx::Erf(%338)\n",
      "  %340 : Float() = onnx::Constant[value={1}]()\n",
      "  %341 : FloatTensor = onnx::Add(%339, %340)\n",
      "  %342 : FloatTensor = onnx::Mul(%336, %341)\n",
      "  %343 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %344 : Float(1, 512, 3072) = onnx::Mul(%342, %343) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1313:0\n",
      "  %346 : Float(1, 512, 768) = onnx::MatMul(%344, %858) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %347 : Float(1, 512, 768) = onnx::Add(%346, %distilbert.transformer.layer.1.ffn.lin2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %348 : Float(1, 512, 768) = onnx::Add(%347, %333) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:256:0\n",
      "  %349 : Tensor = onnx::ReduceMean[axes=[-1]](%348)\n",
      "  %350 : FloatTensor = onnx::Sub(%348, %349)\n",
      "  %351 : Float() = onnx::Constant[value={2}]()\n",
      "  %352 : FloatTensor = onnx::Pow(%350, %351)\n",
      "  %353 : Tensor = onnx::ReduceMean[axes=[-1]](%352)\n",
      "  %354 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %355 : FloatTensor = onnx::Add(%353, %354)\n",
      "  %356 : Tensor = onnx::Sqrt(%355)\n",
      "  %357 : FloatTensor = onnx::Div(%350, %356)\n",
      "  %358 : FloatTensor = onnx::Mul(%357, %distilbert.transformer.layer.1.output_layer_norm.weight)\n",
      "  %359 : Float(1, 512, 768) = onnx::Add(%358, %distilbert.transformer.layer.1.output_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %360 : Tensor = onnx::Shape(%359)\n",
      "  %361 : Tensor = onnx::Constant[value={0}]()\n",
      "  %362 : Long() = onnx::Gather[axis=0](%360, %361) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:155:0\n",
      "  %363 : Tensor = onnx::Shape(%359)\n",
      "  %364 : Tensor = onnx::Constant[value={1}]()\n",
      "  %365 : Long() = onnx::Gather[axis=0](%363, %364) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:156:0\n",
      "  %367 : Float(1, 512, 768) = onnx::MatMul(%359, %859) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %368 : Float(1, 512, 768) = onnx::Add(%367, %distilbert.transformer.layer.2.attention.q_lin.bias)\n",
      "  %372 : Tensor = onnx::Unsqueeze[axes=[0]](%362)\n",
      "  %376 : Tensor = onnx::Concat[axis=0](%372, %860, %861, %862)\n",
      "  %377 : Float(1, 512, 12, 64) = onnx::Reshape(%368, %376) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %378 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%377) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %380 : Float(1, 512, 768) = onnx::MatMul(%359, %863) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %381 : Float(1, 512, 768) = onnx::Add(%380, %distilbert.transformer.layer.2.attention.k_lin.bias)\n",
      "  %385 : Tensor = onnx::Unsqueeze[axes=[0]](%362)\n",
      "  %389 : Tensor = onnx::Concat[axis=0](%385, %864, %865, %866)\n",
      "  %390 : Float(1, 512, 12, 64) = onnx::Reshape(%381, %389) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %392 : Float(1, 512, 768) = onnx::MatMul(%359, %867) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %393 : Float(1, 512, 768) = onnx::Add(%392, %distilbert.transformer.layer.2.attention.v_lin.bias)\n",
      "  %397 : Tensor = onnx::Unsqueeze[axes=[0]](%362)\n",
      "  %401 : Tensor = onnx::Concat[axis=0](%397, %868, %869, %870)\n",
      "  %402 : Float(1, 512, 12, 64) = onnx::Reshape(%393, %401) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %403 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%402) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %404 : Float() = onnx::Constant[value={8}]()\n",
      "  %405 : Float(1, 12, 512, 64) = onnx::Div(%378, %404)\n",
      "  %406 : Float(1, 12, 64, 512) = onnx::Transpose[perm=[0, 2, 3, 1]](%390) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %407 : Float(1, 12, 512, 512) = onnx::MatMul(%405, %406) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %408 : Long() = onnx::Constant[value={0}]()\n",
      "  %409 : Bool(1, 512) = onnx::Equal(%attention_mask, %408) # /opt/conda/lib/python3.7/site-packages/torch/tensor.py:28:0\n",
      "  %412 : Tensor = onnx::Unsqueeze[axes=[0]](%362)\n",
      "  %415 : Tensor = onnx::Unsqueeze[axes=[0]](%365)\n",
      "  %416 : Tensor = onnx::Concat[axis=0](%412, %871, %872, %415)\n",
      "  %417 : Bool(1, 1, 1, 512) = onnx::Reshape(%409, %416) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %418 : Tensor = onnx::Shape(%407)\n",
      "  %419 : Bool(1, 12, 512, 512) = onnx::Expand(%417, %418) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %420 : Tensor = onnx::Cast[to=9](%419)\n",
      "  %421 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %422 : Float(1, 12, 512, 512) = onnx::Where(%420, %421, %407) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:179:0\n",
      "  %423 : Float(1, 12, 512, 512) = onnx::Softmax[axis=3](%422) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %424 : Float(1, 12, 512, 64) = onnx::MatMul(%423, %403) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:188:0\n",
      "  %425 : Float(1, 512, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%424) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %428 : Tensor = onnx::Unsqueeze[axes=[0]](%362)\n",
      "  %431 : Tensor = onnx::Concat[axis=0](%428, %873, %874)\n",
      "  %432 : Float(1, 512, 768) = onnx::Reshape(%425, %431) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %434 : Float(1, 512, 768) = onnx::MatMul(%432, %875) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %435 : Float(1, 512, 768) = onnx::Add(%434, %distilbert.transformer.layer.2.attention.out_lin.bias)\n",
      "  %436 : Float(1, 512, 768) = onnx::Add(%435, %359) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:252:0\n",
      "  %437 : Tensor = onnx::ReduceMean[axes=[-1]](%436)\n",
      "  %438 : FloatTensor = onnx::Sub(%436, %437)\n",
      "  %439 : Float() = onnx::Constant[value={2}]()\n",
      "  %440 : FloatTensor = onnx::Pow(%438, %439)\n",
      "  %441 : Tensor = onnx::ReduceMean[axes=[-1]](%440)\n",
      "  %442 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %443 : FloatTensor = onnx::Add(%441, %442)\n",
      "  %444 : Tensor = onnx::Sqrt(%443)\n",
      "  %445 : FloatTensor = onnx::Div(%438, %444)\n",
      "  %446 : FloatTensor = onnx::Mul(%445, %distilbert.transformer.layer.2.sa_layer_norm.weight)\n",
      "  %447 : Float(1, 512, 768) = onnx::Add(%446, %distilbert.transformer.layer.2.sa_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %449 : Float(1, 512, 3072) = onnx::MatMul(%447, %876) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %450 : Float(1, 512, 3072) = onnx::Add(%449, %distilbert.transformer.layer.2.ffn.lin1.bias)\n",
      "  %451 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %452 : FloatTensor = onnx::Div(%450, %451)\n",
      "  %453 : Tensor = onnx::Erf(%452)\n",
      "  %454 : Float() = onnx::Constant[value={1}]()\n",
      "  %455 : FloatTensor = onnx::Add(%453, %454)\n",
      "  %456 : FloatTensor = onnx::Mul(%450, %455)\n",
      "  %457 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %458 : Float(1, 512, 3072) = onnx::Mul(%456, %457) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1313:0\n",
      "  %460 : Float(1, 512, 768) = onnx::MatMul(%458, %877) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %461 : Float(1, 512, 768) = onnx::Add(%460, %distilbert.transformer.layer.2.ffn.lin2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %462 : Float(1, 512, 768) = onnx::Add(%461, %447) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:256:0\n",
      "  %463 : Tensor = onnx::ReduceMean[axes=[-1]](%462)\n",
      "  %464 : FloatTensor = onnx::Sub(%462, %463)\n",
      "  %465 : Float() = onnx::Constant[value={2}]()\n",
      "  %466 : FloatTensor = onnx::Pow(%464, %465)\n",
      "  %467 : Tensor = onnx::ReduceMean[axes=[-1]](%466)\n",
      "  %468 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %469 : FloatTensor = onnx::Add(%467, %468)\n",
      "  %470 : Tensor = onnx::Sqrt(%469)\n",
      "  %471 : FloatTensor = onnx::Div(%464, %470)\n",
      "  %472 : FloatTensor = onnx::Mul(%471, %distilbert.transformer.layer.2.output_layer_norm.weight)\n",
      "  %473 : Float(1, 512, 768) = onnx::Add(%472, %distilbert.transformer.layer.2.output_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %474 : Tensor = onnx::Shape(%473)\n",
      "  %475 : Tensor = onnx::Constant[value={0}]()\n",
      "  %476 : Long() = onnx::Gather[axis=0](%474, %475) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:155:0\n",
      "  %477 : Tensor = onnx::Shape(%473)\n",
      "  %478 : Tensor = onnx::Constant[value={1}]()\n",
      "  %479 : Long() = onnx::Gather[axis=0](%477, %478) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:156:0\n",
      "  %481 : Float(1, 512, 768) = onnx::MatMul(%473, %878) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %482 : Float(1, 512, 768) = onnx::Add(%481, %distilbert.transformer.layer.3.attention.q_lin.bias)\n",
      "  %486 : Tensor = onnx::Unsqueeze[axes=[0]](%476)\n",
      "  %490 : Tensor = onnx::Concat[axis=0](%486, %879, %880, %881)\n",
      "  %491 : Float(1, 512, 12, 64) = onnx::Reshape(%482, %490) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %492 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%491) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %494 : Float(1, 512, 768) = onnx::MatMul(%473, %882) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %495 : Float(1, 512, 768) = onnx::Add(%494, %distilbert.transformer.layer.3.attention.k_lin.bias)\n",
      "  %499 : Tensor = onnx::Unsqueeze[axes=[0]](%476)\n",
      "  %503 : Tensor = onnx::Concat[axis=0](%499, %883, %884, %885)\n",
      "  %504 : Float(1, 512, 12, 64) = onnx::Reshape(%495, %503) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %506 : Float(1, 512, 768) = onnx::MatMul(%473, %886) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %507 : Float(1, 512, 768) = onnx::Add(%506, %distilbert.transformer.layer.3.attention.v_lin.bias)\n",
      "  %511 : Tensor = onnx::Unsqueeze[axes=[0]](%476)\n",
      "  %515 : Tensor = onnx::Concat[axis=0](%511, %887, %888, %889)\n",
      "  %516 : Float(1, 512, 12, 64) = onnx::Reshape(%507, %515) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %517 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%516) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %518 : Float() = onnx::Constant[value={8}]()\n",
      "  %519 : Float(1, 12, 512, 64) = onnx::Div(%492, %518)\n",
      "  %520 : Float(1, 12, 64, 512) = onnx::Transpose[perm=[0, 2, 3, 1]](%504) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %521 : Float(1, 12, 512, 512) = onnx::MatMul(%519, %520) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %522 : Long() = onnx::Constant[value={0}]()\n",
      "  %523 : Bool(1, 512) = onnx::Equal(%attention_mask, %522) # /opt/conda/lib/python3.7/site-packages/torch/tensor.py:28:0\n",
      "  %526 : Tensor = onnx::Unsqueeze[axes=[0]](%476)\n",
      "  %529 : Tensor = onnx::Unsqueeze[axes=[0]](%479)\n",
      "  %530 : Tensor = onnx::Concat[axis=0](%526, %890, %891, %529)\n",
      "  %531 : Bool(1, 1, 1, 512) = onnx::Reshape(%523, %530) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %532 : Tensor = onnx::Shape(%521)\n",
      "  %533 : Bool(1, 12, 512, 512) = onnx::Expand(%531, %532) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %534 : Tensor = onnx::Cast[to=9](%533)\n",
      "  %535 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %536 : Float(1, 12, 512, 512) = onnx::Where(%534, %535, %521) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:179:0\n",
      "  %537 : Float(1, 12, 512, 512) = onnx::Softmax[axis=3](%536) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %538 : Float(1, 12, 512, 64) = onnx::MatMul(%537, %517) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:188:0\n",
      "  %539 : Float(1, 512, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%538) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %542 : Tensor = onnx::Unsqueeze[axes=[0]](%476)\n",
      "  %545 : Tensor = onnx::Concat[axis=0](%542, %892, %893)\n",
      "  %546 : Float(1, 512, 768) = onnx::Reshape(%539, %545) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %548 : Float(1, 512, 768) = onnx::MatMul(%546, %894) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %549 : Float(1, 512, 768) = onnx::Add(%548, %distilbert.transformer.layer.3.attention.out_lin.bias)\n",
      "  %550 : Float(1, 512, 768) = onnx::Add(%549, %473) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:252:0\n",
      "  %551 : Tensor = onnx::ReduceMean[axes=[-1]](%550)\n",
      "  %552 : FloatTensor = onnx::Sub(%550, %551)\n",
      "  %553 : Float() = onnx::Constant[value={2}]()\n",
      "  %554 : FloatTensor = onnx::Pow(%552, %553)\n",
      "  %555 : Tensor = onnx::ReduceMean[axes=[-1]](%554)\n",
      "  %556 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %557 : FloatTensor = onnx::Add(%555, %556)\n",
      "  %558 : Tensor = onnx::Sqrt(%557)\n",
      "  %559 : FloatTensor = onnx::Div(%552, %558)\n",
      "  %560 : FloatTensor = onnx::Mul(%559, %distilbert.transformer.layer.3.sa_layer_norm.weight)\n",
      "  %561 : Float(1, 512, 768) = onnx::Add(%560, %distilbert.transformer.layer.3.sa_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %563 : Float(1, 512, 3072) = onnx::MatMul(%561, %895) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %564 : Float(1, 512, 3072) = onnx::Add(%563, %distilbert.transformer.layer.3.ffn.lin1.bias)\n",
      "  %565 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %566 : FloatTensor = onnx::Div(%564, %565)\n",
      "  %567 : Tensor = onnx::Erf(%566)\n",
      "  %568 : Float() = onnx::Constant[value={1}]()\n",
      "  %569 : FloatTensor = onnx::Add(%567, %568)\n",
      "  %570 : FloatTensor = onnx::Mul(%564, %569)\n",
      "  %571 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %572 : Float(1, 512, 3072) = onnx::Mul(%570, %571) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1313:0\n",
      "  %574 : Float(1, 512, 768) = onnx::MatMul(%572, %896) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %575 : Float(1, 512, 768) = onnx::Add(%574, %distilbert.transformer.layer.3.ffn.lin2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %576 : Float(1, 512, 768) = onnx::Add(%575, %561) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:256:0\n",
      "  %577 : Tensor = onnx::ReduceMean[axes=[-1]](%576)\n",
      "  %578 : FloatTensor = onnx::Sub(%576, %577)\n",
      "  %579 : Float() = onnx::Constant[value={2}]()\n",
      "  %580 : FloatTensor = onnx::Pow(%578, %579)\n",
      "  %581 : Tensor = onnx::ReduceMean[axes=[-1]](%580)\n",
      "  %582 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %583 : FloatTensor = onnx::Add(%581, %582)\n",
      "  %584 : Tensor = onnx::Sqrt(%583)\n",
      "  %585 : FloatTensor = onnx::Div(%578, %584)\n",
      "  %586 : FloatTensor = onnx::Mul(%585, %distilbert.transformer.layer.3.output_layer_norm.weight)\n",
      "  %587 : Float(1, 512, 768) = onnx::Add(%586, %distilbert.transformer.layer.3.output_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %588 : Tensor = onnx::Shape(%587)\n",
      "  %589 : Tensor = onnx::Constant[value={0}]()\n",
      "  %590 : Long() = onnx::Gather[axis=0](%588, %589) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:155:0\n",
      "  %591 : Tensor = onnx::Shape(%587)\n",
      "  %592 : Tensor = onnx::Constant[value={1}]()\n",
      "  %593 : Long() = onnx::Gather[axis=0](%591, %592) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:156:0\n",
      "  %595 : Float(1, 512, 768) = onnx::MatMul(%587, %897) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %596 : Float(1, 512, 768) = onnx::Add(%595, %distilbert.transformer.layer.4.attention.q_lin.bias)\n",
      "  %600 : Tensor = onnx::Unsqueeze[axes=[0]](%590)\n",
      "  %604 : Tensor = onnx::Concat[axis=0](%600, %898, %899, %900)\n",
      "  %605 : Float(1, 512, 12, 64) = onnx::Reshape(%596, %604) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %606 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%605) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %608 : Float(1, 512, 768) = onnx::MatMul(%587, %901) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %609 : Float(1, 512, 768) = onnx::Add(%608, %distilbert.transformer.layer.4.attention.k_lin.bias)\n",
      "  %613 : Tensor = onnx::Unsqueeze[axes=[0]](%590)\n",
      "  %617 : Tensor = onnx::Concat[axis=0](%613, %902, %903, %904)\n",
      "  %618 : Float(1, 512, 12, 64) = onnx::Reshape(%609, %617) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %620 : Float(1, 512, 768) = onnx::MatMul(%587, %905) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %621 : Float(1, 512, 768) = onnx::Add(%620, %distilbert.transformer.layer.4.attention.v_lin.bias)\n",
      "  %625 : Tensor = onnx::Unsqueeze[axes=[0]](%590)\n",
      "  %629 : Tensor = onnx::Concat[axis=0](%625, %906, %907, %908)\n",
      "  %630 : Float(1, 512, 12, 64) = onnx::Reshape(%621, %629) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %631 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%630) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %632 : Float() = onnx::Constant[value={8}]()\n",
      "  %633 : Float(1, 12, 512, 64) = onnx::Div(%606, %632)\n",
      "  %634 : Float(1, 12, 64, 512) = onnx::Transpose[perm=[0, 2, 3, 1]](%618) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %635 : Float(1, 12, 512, 512) = onnx::MatMul(%633, %634) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %636 : Long() = onnx::Constant[value={0}]()\n",
      "  %637 : Bool(1, 512) = onnx::Equal(%attention_mask, %636) # /opt/conda/lib/python3.7/site-packages/torch/tensor.py:28:0\n",
      "  %640 : Tensor = onnx::Unsqueeze[axes=[0]](%590)\n",
      "  %643 : Tensor = onnx::Unsqueeze[axes=[0]](%593)\n",
      "  %644 : Tensor = onnx::Concat[axis=0](%640, %909, %910, %643)\n",
      "  %645 : Bool(1, 1, 1, 512) = onnx::Reshape(%637, %644) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %646 : Tensor = onnx::Shape(%635)\n",
      "  %647 : Bool(1, 12, 512, 512) = onnx::Expand(%645, %646) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %648 : Tensor = onnx::Cast[to=9](%647)\n",
      "  %649 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %650 : Float(1, 12, 512, 512) = onnx::Where(%648, %649, %635) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:179:0\n",
      "  %651 : Float(1, 12, 512, 512) = onnx::Softmax[axis=3](%650) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %652 : Float(1, 12, 512, 64) = onnx::MatMul(%651, %631) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:188:0\n",
      "  %653 : Float(1, 512, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%652) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %656 : Tensor = onnx::Unsqueeze[axes=[0]](%590)\n",
      "  %659 : Tensor = onnx::Concat[axis=0](%656, %911, %912)\n",
      "  %660 : Float(1, 512, 768) = onnx::Reshape(%653, %659) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %662 : Float(1, 512, 768) = onnx::MatMul(%660, %913) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %663 : Float(1, 512, 768) = onnx::Add(%662, %distilbert.transformer.layer.4.attention.out_lin.bias)\n",
      "  %664 : Float(1, 512, 768) = onnx::Add(%663, %587) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:252:0\n",
      "  %665 : Tensor = onnx::ReduceMean[axes=[-1]](%664)\n",
      "  %666 : FloatTensor = onnx::Sub(%664, %665)\n",
      "  %667 : Float() = onnx::Constant[value={2}]()\n",
      "  %668 : FloatTensor = onnx::Pow(%666, %667)\n",
      "  %669 : Tensor = onnx::ReduceMean[axes=[-1]](%668)\n",
      "  %670 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %671 : FloatTensor = onnx::Add(%669, %670)\n",
      "  %672 : Tensor = onnx::Sqrt(%671)\n",
      "  %673 : FloatTensor = onnx::Div(%666, %672)\n",
      "  %674 : FloatTensor = onnx::Mul(%673, %distilbert.transformer.layer.4.sa_layer_norm.weight)\n",
      "  %675 : Float(1, 512, 768) = onnx::Add(%674, %distilbert.transformer.layer.4.sa_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %677 : Float(1, 512, 3072) = onnx::MatMul(%675, %914) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %678 : Float(1, 512, 3072) = onnx::Add(%677, %distilbert.transformer.layer.4.ffn.lin1.bias)\n",
      "  %679 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %680 : FloatTensor = onnx::Div(%678, %679)\n",
      "  %681 : Tensor = onnx::Erf(%680)\n",
      "  %682 : Float() = onnx::Constant[value={1}]()\n",
      "  %683 : FloatTensor = onnx::Add(%681, %682)\n",
      "  %684 : FloatTensor = onnx::Mul(%678, %683)\n",
      "  %685 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %686 : Float(1, 512, 3072) = onnx::Mul(%684, %685) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1313:0\n",
      "  %688 : Float(1, 512, 768) = onnx::MatMul(%686, %915) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %689 : Float(1, 512, 768) = onnx::Add(%688, %distilbert.transformer.layer.4.ffn.lin2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %690 : Float(1, 512, 768) = onnx::Add(%689, %675) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:256:0\n",
      "  %691 : Tensor = onnx::ReduceMean[axes=[-1]](%690)\n",
      "  %692 : FloatTensor = onnx::Sub(%690, %691)\n",
      "  %693 : Float() = onnx::Constant[value={2}]()\n",
      "  %694 : FloatTensor = onnx::Pow(%692, %693)\n",
      "  %695 : Tensor = onnx::ReduceMean[axes=[-1]](%694)\n",
      "  %696 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %697 : FloatTensor = onnx::Add(%695, %696)\n",
      "  %698 : Tensor = onnx::Sqrt(%697)\n",
      "  %699 : FloatTensor = onnx::Div(%692, %698)\n",
      "  %700 : FloatTensor = onnx::Mul(%699, %distilbert.transformer.layer.4.output_layer_norm.weight)\n",
      "  %701 : Float(1, 512, 768) = onnx::Add(%700, %distilbert.transformer.layer.4.output_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %702 : Tensor = onnx::Shape(%701)\n",
      "  %703 : Tensor = onnx::Constant[value={0}]()\n",
      "  %704 : Long() = onnx::Gather[axis=0](%702, %703) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:155:0\n",
      "  %705 : Tensor = onnx::Shape(%701)\n",
      "  %706 : Tensor = onnx::Constant[value={1}]()\n",
      "  %707 : Long() = onnx::Gather[axis=0](%705, %706) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:156:0\n",
      "  %709 : Float(1, 512, 768) = onnx::MatMul(%701, %916) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %710 : Float(1, 512, 768) = onnx::Add(%709, %distilbert.transformer.layer.5.attention.q_lin.bias)\n",
      "  %714 : Tensor = onnx::Unsqueeze[axes=[0]](%704)\n",
      "  %718 : Tensor = onnx::Concat[axis=0](%714, %917, %918, %919)\n",
      "  %719 : Float(1, 512, 12, 64) = onnx::Reshape(%710, %718) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %720 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%719) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %722 : Float(1, 512, 768) = onnx::MatMul(%701, %920) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %723 : Float(1, 512, 768) = onnx::Add(%722, %distilbert.transformer.layer.5.attention.k_lin.bias)\n",
      "  %727 : Tensor = onnx::Unsqueeze[axes=[0]](%704)\n",
      "  %731 : Tensor = onnx::Concat[axis=0](%727, %921, %922, %923)\n",
      "  %732 : Float(1, 512, 12, 64) = onnx::Reshape(%723, %731) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %734 : Float(1, 512, 768) = onnx::MatMul(%701, %924) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %735 : Float(1, 512, 768) = onnx::Add(%734, %distilbert.transformer.layer.5.attention.v_lin.bias)\n",
      "  %739 : Tensor = onnx::Unsqueeze[axes=[0]](%704)\n",
      "  %743 : Tensor = onnx::Concat[axis=0](%739, %925, %926, %927)\n",
      "  %744 : Float(1, 512, 12, 64) = onnx::Reshape(%735, %743) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %745 : Float(1, 12, 512, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%744) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:166:0\n",
      "  %746 : Float() = onnx::Constant[value={8}]()\n",
      "  %747 : Float(1, 12, 512, 64) = onnx::Div(%720, %746)\n",
      "  %748 : Float(1, 12, 64, 512) = onnx::Transpose[perm=[0, 2, 3, 1]](%732) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %749 : Float(1, 12, 512, 512) = onnx::MatMul(%747, %748) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:177:0\n",
      "  %750 : Long() = onnx::Constant[value={0}]()\n",
      "  %751 : Bool(1, 512) = onnx::Equal(%attention_mask, %750) # /opt/conda/lib/python3.7/site-packages/torch/tensor.py:28:0\n",
      "  %754 : Tensor = onnx::Unsqueeze[axes=[0]](%704)\n",
      "  %757 : Tensor = onnx::Unsqueeze[axes=[0]](%707)\n",
      "  %758 : Tensor = onnx::Concat[axis=0](%754, %928, %929, %757)\n",
      "  %759 : Bool(1, 1, 1, 512) = onnx::Reshape(%751, %758) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %760 : Tensor = onnx::Shape(%749)\n",
      "  %761 : Bool(1, 12, 512, 512) = onnx::Expand(%759, %760) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:178:0\n",
      "  %762 : Tensor = onnx::Cast[to=9](%761)\n",
      "  %763 : Tensor = onnx::Constant[value={-inf}]()\n",
      "  %764 : Float(1, 12, 512, 512) = onnx::Where(%762, %763, %749) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:179:0\n",
      "  %765 : Float(1, 12, 512, 512) = onnx::Softmax[axis=3](%764) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %766 : Float(1, 12, 512, 64) = onnx::MatMul(%765, %745) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:188:0\n",
      "  %767 : Float(1, 512, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%766) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %770 : Tensor = onnx::Unsqueeze[axes=[0]](%704)\n",
      "  %773 : Tensor = onnx::Concat[axis=0](%770, %930, %931)\n",
      "  %774 : Float(1, 512, 768) = onnx::Reshape(%767, %773) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:170:0\n",
      "  %776 : Float(1, 512, 768) = onnx::MatMul(%774, %932) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %777 : Float(1, 512, 768) = onnx::Add(%776, %distilbert.transformer.layer.5.attention.out_lin.bias)\n",
      "  %778 : Float(1, 512, 768) = onnx::Add(%777, %701) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:252:0\n",
      "  %779 : Tensor = onnx::ReduceMean[axes=[-1]](%778)\n",
      "  %780 : FloatTensor = onnx::Sub(%778, %779)\n",
      "  %781 : Float() = onnx::Constant[value={2}]()\n",
      "  %782 : FloatTensor = onnx::Pow(%780, %781)\n",
      "  %783 : Tensor = onnx::ReduceMean[axes=[-1]](%782)\n",
      "  %784 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %785 : FloatTensor = onnx::Add(%783, %784)\n",
      "  %786 : Tensor = onnx::Sqrt(%785)\n",
      "  %787 : FloatTensor = onnx::Div(%780, %786)\n",
      "  %788 : FloatTensor = onnx::Mul(%787, %distilbert.transformer.layer.5.sa_layer_norm.weight)\n",
      "  %789 : Float(1, 512, 768) = onnx::Add(%788, %distilbert.transformer.layer.5.sa_layer_norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956:0\n",
      "  %791 : Float(1, 512, 3072) = onnx::MatMul(%789, %933) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %792 : Float(1, 512, 3072) = onnx::Add(%791, %distilbert.transformer.layer.5.ffn.lin1.bias)\n",
      "  %793 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %794 : FloatTensor = onnx::Div(%792, %793)\n",
      "  %795 : Tensor = onnx::Erf(%794)\n",
      "  %796 : Float() = onnx::Constant[value={1}]()\n",
      "  %797 : FloatTensor = onnx::Add(%795, %796)\n",
      "  %798 : FloatTensor = onnx::Mul(%792, %797)\n",
      "  %799 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %800 : Float(1, 512, 3072) = onnx::Mul(%798, %799) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1313:0\n",
      "  %802 : Float(1, 512, 768) = onnx::MatMul(%800, %934) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1612:0\n",
      "  %803 : Float(1, 512, 768) = onnx::Add(%802, %distilbert.transformer.layer.5.ffn.lin2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %804 : Float(1, 512, 768) = onnx::Add(%803, %789) # /opt/conda/lib/python3.7/site-packages/transformers/modeling_distilbert.py:256:0\n",
      "  %805 : Tensor = onnx::ReduceMean[axes=[-1]](%804)\n",
      "  %806 : FloatTensor = onnx::Sub(%804, %805)\n",
      "  %807 : Float() = onnx::Constant[value={2}]()\n",
      "  %808 : FloatTensor = onnx::Pow(%806, %807)\n",
      "  %809 : Tensor = onnx::ReduceMean[axes=[-1]](%808)\n",
      "  %810 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %811 : FloatTensor = onnx::Add(%809, %810)\n",
      "  %812 : Tensor = onnx::Sqrt(%811)\n",
      "  %813 : FloatTensor = onnx::Div(%806, %812)\n",
      "  %814 : FloatTensor = onnx::Mul(%813, %distilbert.transformer.layer.5.output_layer_norm.weight)\n",
      "  %815 : Float(1, 512, 768) = onnx::Add(%814, %distilbert.transformer.layer.5.output_layer_norm.bias) # <ipython-input-9-d0a4bb00ec17>:49:0\n",
      "  %816 : Tensor = onnx::Constant[value={0}]()\n",
      "  %817 : Float(1, 768) = onnx::Gather[axis=1](%815, %816) # <ipython-input-9-d0a4bb00ec17>:49:0\n",
      "  %818 : Float(1, 768) = onnx::Gemm[alpha=1., beta=1., transB=1](%817, %pre_classifier.weight, %pre_classifier.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1610:0\n",
      "  %819 : Float(1, 768) = onnx::Relu(%818) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %targets : Float(1, 2) = onnx::Gemm[alpha=1., beta=1., transB=1](%819, %classifier.weight, %classifier.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1610:0\n",
      "  return (%targets)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, model_input, \"model_512.onnx\",\n",
    "                  export_params=True,\n",
    "                  input_names=[\"input_ids\", \"attention_mask\"],\n",
    "                  output_names=[\"targets\"],\n",
    "                  dynamic_axes={\n",
    "                      \"input_ids\": {0: \"batch_size\"},\n",
    "                      \"attention_mask\": {0: \"batch_size\"},\n",
    "                      \"targets\": {0: \"batch_size\"}\n",
    "                  },\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that the model is well formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph torch-jit-export (\\n  %input_ids[INT64, batch_sizex512]\\n  %attention_mask[INT64, batch_sizex512]\\n) initializers (\\n  %821[FLOAT, 768x768]\\n  %822[INT64, 1]\\n  %823[INT64, 1]\\n  %824[INT64, 1]\\n  %825[FLOAT, 768x768]\\n  %826[INT64, 1]\\n  %827[INT64, 1]\\n  %828[INT64, 1]\\n  %829[FLOAT, 768x768]\\n  %830[INT64, 1]\\n  %831[INT64, 1]\\n  %832[INT64, 1]\\n  %833[INT64, 1]\\n  %834[INT64, 1]\\n  %835[INT64, 1]\\n  %836[INT64, 1]\\n  %837[FLOAT, 768x768]\\n  %838[FLOAT, 768x3072]\\n  %839[FLOAT, 3072x768]\\n  %840[FLOAT, 768x768]\\n  %841[INT64, 1]\\n  %842[INT64, 1]\\n  %843[INT64, 1]\\n  %844[FLOAT, 768x768]\\n  %845[INT64, 1]\\n  %846[INT64, 1]\\n  %847[INT64, 1]\\n  %848[FLOAT, 768x768]\\n  %849[INT64, 1]\\n  %850[INT64, 1]\\n  %851[INT64, 1]\\n  %852[INT64, 1]\\n  %853[INT64, 1]\\n  %854[INT64, 1]\\n  %855[INT64, 1]\\n  %856[FLOAT, 768x768]\\n  %857[FLOAT, 768x3072]\\n  %858[FLOAT, 3072x768]\\n  %859[FLOAT, 768x768]\\n  %860[INT64, 1]\\n  %861[INT64, 1]\\n  %862[INT64, 1]\\n  %863[FLOAT, 768x768]\\n  %864[INT64, 1]\\n  %865[INT64, 1]\\n  %866[INT64, 1]\\n  %867[FLOAT, 768x768]\\n  %868[INT64, 1]\\n  %869[INT64, 1]\\n  %870[INT64, 1]\\n  %871[INT64, 1]\\n  %872[INT64, 1]\\n  %873[INT64, 1]\\n  %874[INT64, 1]\\n  %875[FLOAT, 768x768]\\n  %876[FLOAT, 768x3072]\\n  %877[FLOAT, 3072x768]\\n  %878[FLOAT, 768x768]\\n  %879[INT64, 1]\\n  %880[INT64, 1]\\n  %881[INT64, 1]\\n  %882[FLOAT, 768x768]\\n  %883[INT64, 1]\\n  %884[INT64, 1]\\n  %885[INT64, 1]\\n  %886[FLOAT, 768x768]\\n  %887[INT64, 1]\\n  %888[INT64, 1]\\n  %889[INT64, 1]\\n  %890[INT64, 1]\\n  %891[INT64, 1]\\n  %892[INT64, 1]\\n  %893[INT64, 1]\\n  %894[FLOAT, 768x768]\\n  %895[FLOAT, 768x3072]\\n  %896[FLOAT, 3072x768]\\n  %897[FLOAT, 768x768]\\n  %898[INT64, 1]\\n  %899[INT64, 1]\\n  %900[INT64, 1]\\n  %901[FLOAT, 768x768]\\n  %902[INT64, 1]\\n  %903[INT64, 1]\\n  %904[INT64, 1]\\n  %905[FLOAT, 768x768]\\n  %906[INT64, 1]\\n  %907[INT64, 1]\\n  %908[INT64, 1]\\n  %909[INT64, 1]\\n  %910[INT64, 1]\\n  %911[INT64, 1]\\n  %912[INT64, 1]\\n  %913[FLOAT, 768x768]\\n  %914[FLOAT, 768x3072]\\n  %915[FLOAT, 3072x768]\\n  %916[FLOAT, 768x768]\\n  %917[INT64, 1]\\n  %918[INT64, 1]\\n  %919[INT64, 1]\\n  %920[FLOAT, 768x768]\\n  %921[INT64, 1]\\n  %922[INT64, 1]\\n  %923[INT64, 1]\\n  %924[FLOAT, 768x768]\\n  %925[INT64, 1]\\n  %926[INT64, 1]\\n  %927[INT64, 1]\\n  %928[INT64, 1]\\n  %929[INT64, 1]\\n  %930[INT64, 1]\\n  %931[INT64, 1]\\n  %932[FLOAT, 768x768]\\n  %933[FLOAT, 768x3072]\\n  %934[FLOAT, 3072x768]\\n  %classifier.bias[FLOAT, 2]\\n  %classifier.weight[FLOAT, 2x768]\\n  %distilbert.embeddings.LayerNorm.bias[FLOAT, 768]\\n  %distilbert.embeddings.LayerNorm.weight[FLOAT, 768]\\n  %distilbert.embeddings.position_embeddings.weight[FLOAT, 512x768]\\n  %distilbert.embeddings.word_embeddings.weight[FLOAT, 30522x768]\\n  %distilbert.transformer.layer.0.attention.k_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.0.attention.out_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.0.attention.q_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.0.attention.v_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.0.ffn.lin1.bias[FLOAT, 3072]\\n  %distilbert.transformer.layer.0.ffn.lin2.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.0.output_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.0.output_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.0.sa_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.0.sa_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.1.attention.k_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.1.attention.out_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.1.attention.q_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.1.attention.v_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.1.ffn.lin1.bias[FLOAT, 3072]\\n  %distilbert.transformer.layer.1.ffn.lin2.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.1.output_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.1.output_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.1.sa_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.1.sa_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.2.attention.k_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.2.attention.out_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.2.attention.q_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.2.attention.v_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.2.ffn.lin1.bias[FLOAT, 3072]\\n  %distilbert.transformer.layer.2.ffn.lin2.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.2.output_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.2.output_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.2.sa_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.2.sa_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.3.attention.k_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.3.attention.out_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.3.attention.q_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.3.attention.v_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.3.ffn.lin1.bias[FLOAT, 3072]\\n  %distilbert.transformer.layer.3.ffn.lin2.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.3.output_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.3.output_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.3.sa_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.3.sa_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.4.attention.k_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.4.attention.out_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.4.attention.q_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.4.attention.v_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.4.ffn.lin1.bias[FLOAT, 3072]\\n  %distilbert.transformer.layer.4.ffn.lin2.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.4.output_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.4.output_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.4.sa_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.4.sa_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.5.attention.k_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.5.attention.out_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.5.attention.q_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.5.attention.v_lin.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.5.ffn.lin1.bias[FLOAT, 3072]\\n  %distilbert.transformer.layer.5.ffn.lin2.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.5.output_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.5.output_layer_norm.weight[FLOAT, 768]\\n  %distilbert.transformer.layer.5.sa_layer_norm.bias[FLOAT, 768]\\n  %distilbert.transformer.layer.5.sa_layer_norm.weight[FLOAT, 768]\\n  %pre_classifier.bias[FLOAT, 768]\\n  %pre_classifier.weight[FLOAT, 768x768]\\n) {\\n  %106 = Shape(%input_ids)\\n  %107 = Constant[value = <Scalar Tensor []>]()\\n  %108 = Gather[axis = 0](%106, %107)\\n  %109 = Unsqueeze[axes = [0]](%108)\\n  %110 = ConstantOfShape[value = <Tensor>](%109)\\n  %111 = NonZero(%110)\\n  %112 = Transpose[perm = [1, 0]](%111)\\n  %113 = Squeeze[axes = [1]](%112)\\n  %114 = Cast[to = 7](%113)\\n  %115 = Unsqueeze[axes = [0]](%114)\\n  %116 = Shape(%input_ids)\\n  %117 = Expand(%115, %116)\\n  %118 = Gather(%distilbert.embeddings.word_embeddings.weight, %input_ids)\\n  %119 = Gather(%distilbert.embeddings.position_embeddings.weight, %117)\\n  %120 = Add(%118, %119)\\n  %121 = ReduceMean[axes = [-1]](%120)\\n  %122 = Sub(%120, %121)\\n  %123 = Constant[value = <Scalar Tensor []>]()\\n  %124 = Pow(%122, %123)\\n  %125 = ReduceMean[axes = [-1]](%124)\\n  %126 = Constant[value = <Scalar Tensor []>]()\\n  %127 = Add(%125, %126)\\n  %128 = Sqrt(%127)\\n  %129 = Div(%122, %128)\\n  %130 = Mul(%129, %distilbert.embeddings.LayerNorm.weight)\\n  %131 = Add(%130, %distilbert.embeddings.LayerNorm.bias)\\n  %132 = Shape(%131)\\n  %133 = Constant[value = <Scalar Tensor []>]()\\n  %134 = Gather[axis = 0](%132, %133)\\n  %135 = Shape(%131)\\n  %136 = Constant[value = <Scalar Tensor []>]()\\n  %137 = Gather[axis = 0](%135, %136)\\n  %139 = MatMul(%131, %821)\\n  %140 = Add(%139, %distilbert.transformer.layer.0.attention.q_lin.bias)\\n  %144 = Unsqueeze[axes = [0]](%134)\\n  %148 = Concat[axis = 0](%144, %822, %823, %824)\\n  %149 = Reshape(%140, %148)\\n  %150 = Transpose[perm = [0, 2, 1, 3]](%149)\\n  %152 = MatMul(%131, %825)\\n  %153 = Add(%152, %distilbert.transformer.layer.0.attention.k_lin.bias)\\n  %157 = Unsqueeze[axes = [0]](%134)\\n  %161 = Concat[axis = 0](%157, %826, %827, %828)\\n  %162 = Reshape(%153, %161)\\n  %164 = MatMul(%131, %829)\\n  %165 = Add(%164, %distilbert.transformer.layer.0.attention.v_lin.bias)\\n  %169 = Unsqueeze[axes = [0]](%134)\\n  %173 = Concat[axis = 0](%169, %830, %831, %832)\\n  %174 = Reshape(%165, %173)\\n  %175 = Transpose[perm = [0, 2, 1, 3]](%174)\\n  %176 = Constant[value = <Scalar Tensor []>]()\\n  %177 = Div(%150, %176)\\n  %178 = Transpose[perm = [0, 2, 3, 1]](%162)\\n  %179 = MatMul(%177, %178)\\n  %180 = Constant[value = <Scalar Tensor []>]()\\n  %181 = Equal(%attention_mask, %180)\\n  %184 = Unsqueeze[axes = [0]](%134)\\n  %187 = Unsqueeze[axes = [0]](%137)\\n  %188 = Concat[axis = 0](%184, %833, %834, %187)\\n  %189 = Reshape(%181, %188)\\n  %190 = Shape(%179)\\n  %191 = Expand(%189, %190)\\n  %192 = Cast[to = 9](%191)\\n  %193 = Constant[value = <Scalar Tensor []>]()\\n  %194 = Where(%192, %193, %179)\\n  %195 = Softmax[axis = 3](%194)\\n  %196 = MatMul(%195, %175)\\n  %197 = Transpose[perm = [0, 2, 1, 3]](%196)\\n  %200 = Unsqueeze[axes = [0]](%134)\\n  %203 = Concat[axis = 0](%200, %835, %836)\\n  %204 = Reshape(%197, %203)\\n  %206 = MatMul(%204, %837)\\n  %207 = Add(%206, %distilbert.transformer.layer.0.attention.out_lin.bias)\\n  %208 = Add(%207, %131)\\n  %209 = ReduceMean[axes = [-1]](%208)\\n  %210 = Sub(%208, %209)\\n  %211 = Constant[value = <Scalar Tensor []>]()\\n  %212 = Pow(%210, %211)\\n  %213 = ReduceMean[axes = [-1]](%212)\\n  %214 = Constant[value = <Scalar Tensor []>]()\\n  %215 = Add(%213, %214)\\n  %216 = Sqrt(%215)\\n  %217 = Div(%210, %216)\\n  %218 = Mul(%217, %distilbert.transformer.layer.0.sa_layer_norm.weight)\\n  %219 = Add(%218, %distilbert.transformer.layer.0.sa_layer_norm.bias)\\n  %221 = MatMul(%219, %838)\\n  %222 = Add(%221, %distilbert.transformer.layer.0.ffn.lin1.bias)\\n  %223 = Constant[value = <Scalar Tensor []>]()\\n  %224 = Div(%222, %223)\\n  %225 = Erf(%224)\\n  %226 = Constant[value = <Scalar Tensor []>]()\\n  %227 = Add(%225, %226)\\n  %228 = Mul(%222, %227)\\n  %229 = Constant[value = <Scalar Tensor []>]()\\n  %230 = Mul(%228, %229)\\n  %232 = MatMul(%230, %839)\\n  %233 = Add(%232, %distilbert.transformer.layer.0.ffn.lin2.bias)\\n  %234 = Add(%233, %219)\\n  %235 = ReduceMean[axes = [-1]](%234)\\n  %236 = Sub(%234, %235)\\n  %237 = Constant[value = <Scalar Tensor []>]()\\n  %238 = Pow(%236, %237)\\n  %239 = ReduceMean[axes = [-1]](%238)\\n  %240 = Constant[value = <Scalar Tensor []>]()\\n  %241 = Add(%239, %240)\\n  %242 = Sqrt(%241)\\n  %243 = Div(%236, %242)\\n  %244 = Mul(%243, %distilbert.transformer.layer.0.output_layer_norm.weight)\\n  %245 = Add(%244, %distilbert.transformer.layer.0.output_layer_norm.bias)\\n  %246 = Shape(%245)\\n  %247 = Constant[value = <Scalar Tensor []>]()\\n  %248 = Gather[axis = 0](%246, %247)\\n  %249 = Shape(%245)\\n  %250 = Constant[value = <Scalar Tensor []>]()\\n  %251 = Gather[axis = 0](%249, %250)\\n  %253 = MatMul(%245, %840)\\n  %254 = Add(%253, %distilbert.transformer.layer.1.attention.q_lin.bias)\\n  %258 = Unsqueeze[axes = [0]](%248)\\n  %262 = Concat[axis = 0](%258, %841, %842, %843)\\n  %263 = Reshape(%254, %262)\\n  %264 = Transpose[perm = [0, 2, 1, 3]](%263)\\n  %266 = MatMul(%245, %844)\\n  %267 = Add(%266, %distilbert.transformer.layer.1.attention.k_lin.bias)\\n  %271 = Unsqueeze[axes = [0]](%248)\\n  %275 = Concat[axis = 0](%271, %845, %846, %847)\\n  %276 = Reshape(%267, %275)\\n  %278 = MatMul(%245, %848)\\n  %279 = Add(%278, %distilbert.transformer.layer.1.attention.v_lin.bias)\\n  %283 = Unsqueeze[axes = [0]](%248)\\n  %287 = Concat[axis = 0](%283, %849, %850, %851)\\n  %288 = Reshape(%279, %287)\\n  %289 = Transpose[perm = [0, 2, 1, 3]](%288)\\n  %290 = Constant[value = <Scalar Tensor []>]()\\n  %291 = Div(%264, %290)\\n  %292 = Transpose[perm = [0, 2, 3, 1]](%276)\\n  %293 = MatMul(%291, %292)\\n  %294 = Constant[value = <Scalar Tensor []>]()\\n  %295 = Equal(%attention_mask, %294)\\n  %298 = Unsqueeze[axes = [0]](%248)\\n  %301 = Unsqueeze[axes = [0]](%251)\\n  %302 = Concat[axis = 0](%298, %852, %853, %301)\\n  %303 = Reshape(%295, %302)\\n  %304 = Shape(%293)\\n  %305 = Expand(%303, %304)\\n  %306 = Cast[to = 9](%305)\\n  %307 = Constant[value = <Scalar Tensor []>]()\\n  %308 = Where(%306, %307, %293)\\n  %309 = Softmax[axis = 3](%308)\\n  %310 = MatMul(%309, %289)\\n  %311 = Transpose[perm = [0, 2, 1, 3]](%310)\\n  %314 = Unsqueeze[axes = [0]](%248)\\n  %317 = Concat[axis = 0](%314, %854, %855)\\n  %318 = Reshape(%311, %317)\\n  %320 = MatMul(%318, %856)\\n  %321 = Add(%320, %distilbert.transformer.layer.1.attention.out_lin.bias)\\n  %322 = Add(%321, %245)\\n  %323 = ReduceMean[axes = [-1]](%322)\\n  %324 = Sub(%322, %323)\\n  %325 = Constant[value = <Scalar Tensor []>]()\\n  %326 = Pow(%324, %325)\\n  %327 = ReduceMean[axes = [-1]](%326)\\n  %328 = Constant[value = <Scalar Tensor []>]()\\n  %329 = Add(%327, %328)\\n  %330 = Sqrt(%329)\\n  %331 = Div(%324, %330)\\n  %332 = Mul(%331, %distilbert.transformer.layer.1.sa_layer_norm.weight)\\n  %333 = Add(%332, %distilbert.transformer.layer.1.sa_layer_norm.bias)\\n  %335 = MatMul(%333, %857)\\n  %336 = Add(%335, %distilbert.transformer.layer.1.ffn.lin1.bias)\\n  %337 = Constant[value = <Scalar Tensor []>]()\\n  %338 = Div(%336, %337)\\n  %339 = Erf(%338)\\n  %340 = Constant[value = <Scalar Tensor []>]()\\n  %341 = Add(%339, %340)\\n  %342 = Mul(%336, %341)\\n  %343 = Constant[value = <Scalar Tensor []>]()\\n  %344 = Mul(%342, %343)\\n  %346 = MatMul(%344, %858)\\n  %347 = Add(%346, %distilbert.transformer.layer.1.ffn.lin2.bias)\\n  %348 = Add(%347, %333)\\n  %349 = ReduceMean[axes = [-1]](%348)\\n  %350 = Sub(%348, %349)\\n  %351 = Constant[value = <Scalar Tensor []>]()\\n  %352 = Pow(%350, %351)\\n  %353 = ReduceMean[axes = [-1]](%352)\\n  %354 = Constant[value = <Scalar Tensor []>]()\\n  %355 = Add(%353, %354)\\n  %356 = Sqrt(%355)\\n  %357 = Div(%350, %356)\\n  %358 = Mul(%357, %distilbert.transformer.layer.1.output_layer_norm.weight)\\n  %359 = Add(%358, %distilbert.transformer.layer.1.output_layer_norm.bias)\\n  %360 = Shape(%359)\\n  %361 = Constant[value = <Scalar Tensor []>]()\\n  %362 = Gather[axis = 0](%360, %361)\\n  %363 = Shape(%359)\\n  %364 = Constant[value = <Scalar Tensor []>]()\\n  %365 = Gather[axis = 0](%363, %364)\\n  %367 = MatMul(%359, %859)\\n  %368 = Add(%367, %distilbert.transformer.layer.2.attention.q_lin.bias)\\n  %372 = Unsqueeze[axes = [0]](%362)\\n  %376 = Concat[axis = 0](%372, %860, %861, %862)\\n  %377 = Reshape(%368, %376)\\n  %378 = Transpose[perm = [0, 2, 1, 3]](%377)\\n  %380 = MatMul(%359, %863)\\n  %381 = Add(%380, %distilbert.transformer.layer.2.attention.k_lin.bias)\\n  %385 = Unsqueeze[axes = [0]](%362)\\n  %389 = Concat[axis = 0](%385, %864, %865, %866)\\n  %390 = Reshape(%381, %389)\\n  %392 = MatMul(%359, %867)\\n  %393 = Add(%392, %distilbert.transformer.layer.2.attention.v_lin.bias)\\n  %397 = Unsqueeze[axes = [0]](%362)\\n  %401 = Concat[axis = 0](%397, %868, %869, %870)\\n  %402 = Reshape(%393, %401)\\n  %403 = Transpose[perm = [0, 2, 1, 3]](%402)\\n  %404 = Constant[value = <Scalar Tensor []>]()\\n  %405 = Div(%378, %404)\\n  %406 = Transpose[perm = [0, 2, 3, 1]](%390)\\n  %407 = MatMul(%405, %406)\\n  %408 = Constant[value = <Scalar Tensor []>]()\\n  %409 = Equal(%attention_mask, %408)\\n  %412 = Unsqueeze[axes = [0]](%362)\\n  %415 = Unsqueeze[axes = [0]](%365)\\n  %416 = Concat[axis = 0](%412, %871, %872, %415)\\n  %417 = Reshape(%409, %416)\\n  %418 = Shape(%407)\\n  %419 = Expand(%417, %418)\\n  %420 = Cast[to = 9](%419)\\n  %421 = Constant[value = <Scalar Tensor []>]()\\n  %422 = Where(%420, %421, %407)\\n  %423 = Softmax[axis = 3](%422)\\n  %424 = MatMul(%423, %403)\\n  %425 = Transpose[perm = [0, 2, 1, 3]](%424)\\n  %428 = Unsqueeze[axes = [0]](%362)\\n  %431 = Concat[axis = 0](%428, %873, %874)\\n  %432 = Reshape(%425, %431)\\n  %434 = MatMul(%432, %875)\\n  %435 = Add(%434, %distilbert.transformer.layer.2.attention.out_lin.bias)\\n  %436 = Add(%435, %359)\\n  %437 = ReduceMean[axes = [-1]](%436)\\n  %438 = Sub(%436, %437)\\n  %439 = Constant[value = <Scalar Tensor []>]()\\n  %440 = Pow(%438, %439)\\n  %441 = ReduceMean[axes = [-1]](%440)\\n  %442 = Constant[value = <Scalar Tensor []>]()\\n  %443 = Add(%441, %442)\\n  %444 = Sqrt(%443)\\n  %445 = Div(%438, %444)\\n  %446 = Mul(%445, %distilbert.transformer.layer.2.sa_layer_norm.weight)\\n  %447 = Add(%446, %distilbert.transformer.layer.2.sa_layer_norm.bias)\\n  %449 = MatMul(%447, %876)\\n  %450 = Add(%449, %distilbert.transformer.layer.2.ffn.lin1.bias)\\n  %451 = Constant[value = <Scalar Tensor []>]()\\n  %452 = Div(%450, %451)\\n  %453 = Erf(%452)\\n  %454 = Constant[value = <Scalar Tensor []>]()\\n  %455 = Add(%453, %454)\\n  %456 = Mul(%450, %455)\\n  %457 = Constant[value = <Scalar Tensor []>]()\\n  %458 = Mul(%456, %457)\\n  %460 = MatMul(%458, %877)\\n  %461 = Add(%460, %distilbert.transformer.layer.2.ffn.lin2.bias)\\n  %462 = Add(%461, %447)\\n  %463 = ReduceMean[axes = [-1]](%462)\\n  %464 = Sub(%462, %463)\\n  %465 = Constant[value = <Scalar Tensor []>]()\\n  %466 = Pow(%464, %465)\\n  %467 = ReduceMean[axes = [-1]](%466)\\n  %468 = Constant[value = <Scalar Tensor []>]()\\n  %469 = Add(%467, %468)\\n  %470 = Sqrt(%469)\\n  %471 = Div(%464, %470)\\n  %472 = Mul(%471, %distilbert.transformer.layer.2.output_layer_norm.weight)\\n  %473 = Add(%472, %distilbert.transformer.layer.2.output_layer_norm.bias)\\n  %474 = Shape(%473)\\n  %475 = Constant[value = <Scalar Tensor []>]()\\n  %476 = Gather[axis = 0](%474, %475)\\n  %477 = Shape(%473)\\n  %478 = Constant[value = <Scalar Tensor []>]()\\n  %479 = Gather[axis = 0](%477, %478)\\n  %481 = MatMul(%473, %878)\\n  %482 = Add(%481, %distilbert.transformer.layer.3.attention.q_lin.bias)\\n  %486 = Unsqueeze[axes = [0]](%476)\\n  %490 = Concat[axis = 0](%486, %879, %880, %881)\\n  %491 = Reshape(%482, %490)\\n  %492 = Transpose[perm = [0, 2, 1, 3]](%491)\\n  %494 = MatMul(%473, %882)\\n  %495 = Add(%494, %distilbert.transformer.layer.3.attention.k_lin.bias)\\n  %499 = Unsqueeze[axes = [0]](%476)\\n  %503 = Concat[axis = 0](%499, %883, %884, %885)\\n  %504 = Reshape(%495, %503)\\n  %506 = MatMul(%473, %886)\\n  %507 = Add(%506, %distilbert.transformer.layer.3.attention.v_lin.bias)\\n  %511 = Unsqueeze[axes = [0]](%476)\\n  %515 = Concat[axis = 0](%511, %887, %888, %889)\\n  %516 = Reshape(%507, %515)\\n  %517 = Transpose[perm = [0, 2, 1, 3]](%516)\\n  %518 = Constant[value = <Scalar Tensor []>]()\\n  %519 = Div(%492, %518)\\n  %520 = Transpose[perm = [0, 2, 3, 1]](%504)\\n  %521 = MatMul(%519, %520)\\n  %522 = Constant[value = <Scalar Tensor []>]()\\n  %523 = Equal(%attention_mask, %522)\\n  %526 = Unsqueeze[axes = [0]](%476)\\n  %529 = Unsqueeze[axes = [0]](%479)\\n  %530 = Concat[axis = 0](%526, %890, %891, %529)\\n  %531 = Reshape(%523, %530)\\n  %532 = Shape(%521)\\n  %533 = Expand(%531, %532)\\n  %534 = Cast[to = 9](%533)\\n  %535 = Constant[value = <Scalar Tensor []>]()\\n  %536 = Where(%534, %535, %521)\\n  %537 = Softmax[axis = 3](%536)\\n  %538 = MatMul(%537, %517)\\n  %539 = Transpose[perm = [0, 2, 1, 3]](%538)\\n  %542 = Unsqueeze[axes = [0]](%476)\\n  %545 = Concat[axis = 0](%542, %892, %893)\\n  %546 = Reshape(%539, %545)\\n  %548 = MatMul(%546, %894)\\n  %549 = Add(%548, %distilbert.transformer.layer.3.attention.out_lin.bias)\\n  %550 = Add(%549, %473)\\n  %551 = ReduceMean[axes = [-1]](%550)\\n  %552 = Sub(%550, %551)\\n  %553 = Constant[value = <Scalar Tensor []>]()\\n  %554 = Pow(%552, %553)\\n  %555 = ReduceMean[axes = [-1]](%554)\\n  %556 = Constant[value = <Scalar Tensor []>]()\\n  %557 = Add(%555, %556)\\n  %558 = Sqrt(%557)\\n  %559 = Div(%552, %558)\\n  %560 = Mul(%559, %distilbert.transformer.layer.3.sa_layer_norm.weight)\\n  %561 = Add(%560, %distilbert.transformer.layer.3.sa_layer_norm.bias)\\n  %563 = MatMul(%561, %895)\\n  %564 = Add(%563, %distilbert.transformer.layer.3.ffn.lin1.bias)\\n  %565 = Constant[value = <Scalar Tensor []>]()\\n  %566 = Div(%564, %565)\\n  %567 = Erf(%566)\\n  %568 = Constant[value = <Scalar Tensor []>]()\\n  %569 = Add(%567, %568)\\n  %570 = Mul(%564, %569)\\n  %571 = Constant[value = <Scalar Tensor []>]()\\n  %572 = Mul(%570, %571)\\n  %574 = MatMul(%572, %896)\\n  %575 = Add(%574, %distilbert.transformer.layer.3.ffn.lin2.bias)\\n  %576 = Add(%575, %561)\\n  %577 = ReduceMean[axes = [-1]](%576)\\n  %578 = Sub(%576, %577)\\n  %579 = Constant[value = <Scalar Tensor []>]()\\n  %580 = Pow(%578, %579)\\n  %581 = ReduceMean[axes = [-1]](%580)\\n  %582 = Constant[value = <Scalar Tensor []>]()\\n  %583 = Add(%581, %582)\\n  %584 = Sqrt(%583)\\n  %585 = Div(%578, %584)\\n  %586 = Mul(%585, %distilbert.transformer.layer.3.output_layer_norm.weight)\\n  %587 = Add(%586, %distilbert.transformer.layer.3.output_layer_norm.bias)\\n  %588 = Shape(%587)\\n  %589 = Constant[value = <Scalar Tensor []>]()\\n  %590 = Gather[axis = 0](%588, %589)\\n  %591 = Shape(%587)\\n  %592 = Constant[value = <Scalar Tensor []>]()\\n  %593 = Gather[axis = 0](%591, %592)\\n  %595 = MatMul(%587, %897)\\n  %596 = Add(%595, %distilbert.transformer.layer.4.attention.q_lin.bias)\\n  %600 = Unsqueeze[axes = [0]](%590)\\n  %604 = Concat[axis = 0](%600, %898, %899, %900)\\n  %605 = Reshape(%596, %604)\\n  %606 = Transpose[perm = [0, 2, 1, 3]](%605)\\n  %608 = MatMul(%587, %901)\\n  %609 = Add(%608, %distilbert.transformer.layer.4.attention.k_lin.bias)\\n  %613 = Unsqueeze[axes = [0]](%590)\\n  %617 = Concat[axis = 0](%613, %902, %903, %904)\\n  %618 = Reshape(%609, %617)\\n  %620 = MatMul(%587, %905)\\n  %621 = Add(%620, %distilbert.transformer.layer.4.attention.v_lin.bias)\\n  %625 = Unsqueeze[axes = [0]](%590)\\n  %629 = Concat[axis = 0](%625, %906, %907, %908)\\n  %630 = Reshape(%621, %629)\\n  %631 = Transpose[perm = [0, 2, 1, 3]](%630)\\n  %632 = Constant[value = <Scalar Tensor []>]()\\n  %633 = Div(%606, %632)\\n  %634 = Transpose[perm = [0, 2, 3, 1]](%618)\\n  %635 = MatMul(%633, %634)\\n  %636 = Constant[value = <Scalar Tensor []>]()\\n  %637 = Equal(%attention_mask, %636)\\n  %640 = Unsqueeze[axes = [0]](%590)\\n  %643 = Unsqueeze[axes = [0]](%593)\\n  %644 = Concat[axis = 0](%640, %909, %910, %643)\\n  %645 = Reshape(%637, %644)\\n  %646 = Shape(%635)\\n  %647 = Expand(%645, %646)\\n  %648 = Cast[to = 9](%647)\\n  %649 = Constant[value = <Scalar Tensor []>]()\\n  %650 = Where(%648, %649, %635)\\n  %651 = Softmax[axis = 3](%650)\\n  %652 = MatMul(%651, %631)\\n  %653 = Transpose[perm = [0, 2, 1, 3]](%652)\\n  %656 = Unsqueeze[axes = [0]](%590)\\n  %659 = Concat[axis = 0](%656, %911, %912)\\n  %660 = Reshape(%653, %659)\\n  %662 = MatMul(%660, %913)\\n  %663 = Add(%662, %distilbert.transformer.layer.4.attention.out_lin.bias)\\n  %664 = Add(%663, %587)\\n  %665 = ReduceMean[axes = [-1]](%664)\\n  %666 = Sub(%664, %665)\\n  %667 = Constant[value = <Scalar Tensor []>]()\\n  %668 = Pow(%666, %667)\\n  %669 = ReduceMean[axes = [-1]](%668)\\n  %670 = Constant[value = <Scalar Tensor []>]()\\n  %671 = Add(%669, %670)\\n  %672 = Sqrt(%671)\\n  %673 = Div(%666, %672)\\n  %674 = Mul(%673, %distilbert.transformer.layer.4.sa_layer_norm.weight)\\n  %675 = Add(%674, %distilbert.transformer.layer.4.sa_layer_norm.bias)\\n  %677 = MatMul(%675, %914)\\n  %678 = Add(%677, %distilbert.transformer.layer.4.ffn.lin1.bias)\\n  %679 = Constant[value = <Scalar Tensor []>]()\\n  %680 = Div(%678, %679)\\n  %681 = Erf(%680)\\n  %682 = Constant[value = <Scalar Tensor []>]()\\n  %683 = Add(%681, %682)\\n  %684 = Mul(%678, %683)\\n  %685 = Constant[value = <Scalar Tensor []>]()\\n  %686 = Mul(%684, %685)\\n  %688 = MatMul(%686, %915)\\n  %689 = Add(%688, %distilbert.transformer.layer.4.ffn.lin2.bias)\\n  %690 = Add(%689, %675)\\n  %691 = ReduceMean[axes = [-1]](%690)\\n  %692 = Sub(%690, %691)\\n  %693 = Constant[value = <Scalar Tensor []>]()\\n  %694 = Pow(%692, %693)\\n  %695 = ReduceMean[axes = [-1]](%694)\\n  %696 = Constant[value = <Scalar Tensor []>]()\\n  %697 = Add(%695, %696)\\n  %698 = Sqrt(%697)\\n  %699 = Div(%692, %698)\\n  %700 = Mul(%699, %distilbert.transformer.layer.4.output_layer_norm.weight)\\n  %701 = Add(%700, %distilbert.transformer.layer.4.output_layer_norm.bias)\\n  %702 = Shape(%701)\\n  %703 = Constant[value = <Scalar Tensor []>]()\\n  %704 = Gather[axis = 0](%702, %703)\\n  %705 = Shape(%701)\\n  %706 = Constant[value = <Scalar Tensor []>]()\\n  %707 = Gather[axis = 0](%705, %706)\\n  %709 = MatMul(%701, %916)\\n  %710 = Add(%709, %distilbert.transformer.layer.5.attention.q_lin.bias)\\n  %714 = Unsqueeze[axes = [0]](%704)\\n  %718 = Concat[axis = 0](%714, %917, %918, %919)\\n  %719 = Reshape(%710, %718)\\n  %720 = Transpose[perm = [0, 2, 1, 3]](%719)\\n  %722 = MatMul(%701, %920)\\n  %723 = Add(%722, %distilbert.transformer.layer.5.attention.k_lin.bias)\\n  %727 = Unsqueeze[axes = [0]](%704)\\n  %731 = Concat[axis = 0](%727, %921, %922, %923)\\n  %732 = Reshape(%723, %731)\\n  %734 = MatMul(%701, %924)\\n  %735 = Add(%734, %distilbert.transformer.layer.5.attention.v_lin.bias)\\n  %739 = Unsqueeze[axes = [0]](%704)\\n  %743 = Concat[axis = 0](%739, %925, %926, %927)\\n  %744 = Reshape(%735, %743)\\n  %745 = Transpose[perm = [0, 2, 1, 3]](%744)\\n  %746 = Constant[value = <Scalar Tensor []>]()\\n  %747 = Div(%720, %746)\\n  %748 = Transpose[perm = [0, 2, 3, 1]](%732)\\n  %749 = MatMul(%747, %748)\\n  %750 = Constant[value = <Scalar Tensor []>]()\\n  %751 = Equal(%attention_mask, %750)\\n  %754 = Unsqueeze[axes = [0]](%704)\\n  %757 = Unsqueeze[axes = [0]](%707)\\n  %758 = Concat[axis = 0](%754, %928, %929, %757)\\n  %759 = Reshape(%751, %758)\\n  %760 = Shape(%749)\\n  %761 = Expand(%759, %760)\\n  %762 = Cast[to = 9](%761)\\n  %763 = Constant[value = <Scalar Tensor []>]()\\n  %764 = Where(%762, %763, %749)\\n  %765 = Softmax[axis = 3](%764)\\n  %766 = MatMul(%765, %745)\\n  %767 = Transpose[perm = [0, 2, 1, 3]](%766)\\n  %770 = Unsqueeze[axes = [0]](%704)\\n  %773 = Concat[axis = 0](%770, %930, %931)\\n  %774 = Reshape(%767, %773)\\n  %776 = MatMul(%774, %932)\\n  %777 = Add(%776, %distilbert.transformer.layer.5.attention.out_lin.bias)\\n  %778 = Add(%777, %701)\\n  %779 = ReduceMean[axes = [-1]](%778)\\n  %780 = Sub(%778, %779)\\n  %781 = Constant[value = <Scalar Tensor []>]()\\n  %782 = Pow(%780, %781)\\n  %783 = ReduceMean[axes = [-1]](%782)\\n  %784 = Constant[value = <Scalar Tensor []>]()\\n  %785 = Add(%783, %784)\\n  %786 = Sqrt(%785)\\n  %787 = Div(%780, %786)\\n  %788 = Mul(%787, %distilbert.transformer.layer.5.sa_layer_norm.weight)\\n  %789 = Add(%788, %distilbert.transformer.layer.5.sa_layer_norm.bias)\\n  %791 = MatMul(%789, %933)\\n  %792 = Add(%791, %distilbert.transformer.layer.5.ffn.lin1.bias)\\n  %793 = Constant[value = <Scalar Tensor []>]()\\n  %794 = Div(%792, %793)\\n  %795 = Erf(%794)\\n  %796 = Constant[value = <Scalar Tensor []>]()\\n  %797 = Add(%795, %796)\\n  %798 = Mul(%792, %797)\\n  %799 = Constant[value = <Scalar Tensor []>]()\\n  %800 = Mul(%798, %799)\\n  %802 = MatMul(%800, %934)\\n  %803 = Add(%802, %distilbert.transformer.layer.5.ffn.lin2.bias)\\n  %804 = Add(%803, %789)\\n  %805 = ReduceMean[axes = [-1]](%804)\\n  %806 = Sub(%804, %805)\\n  %807 = Constant[value = <Scalar Tensor []>]()\\n  %808 = Pow(%806, %807)\\n  %809 = ReduceMean[axes = [-1]](%808)\\n  %810 = Constant[value = <Scalar Tensor []>]()\\n  %811 = Add(%809, %810)\\n  %812 = Sqrt(%811)\\n  %813 = Div(%806, %812)\\n  %814 = Mul(%813, %distilbert.transformer.layer.5.output_layer_norm.weight)\\n  %815 = Add(%814, %distilbert.transformer.layer.5.output_layer_norm.bias)\\n  %816 = Constant[value = <Scalar Tensor []>]()\\n  %817 = Gather[axis = 1](%815, %816)\\n  %818 = Gemm[alpha = 1, beta = 1, transB = 1](%817, %pre_classifier.weight, %pre_classifier.bias)\\n  %819 = Relu(%818)\\n  %targets = Gemm[alpha = 1, beta = 1, transB = 1](%819, %classifier.weight, %classifier.bias)\\n  return %targets\\n}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load('model_512.onnx')\n",
    "onnx.checker.check_model(onnx_model, full_check=True)\n",
    "onnx.helper.printable_graph(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime_tools import optimizer\n",
    "optimized_model_512 = optimizer.optimize_model(\"model_512.onnx\", model_type='bert', \n",
    "                                               num_heads=12, hidden_size=768,\n",
    "                                              use_gpu=False, opt_level=99)\n",
    "\n",
    "optimized_model_512.save_model_to_file(\"optimized_512.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GPU Inference, we can use following methods:\n",
    "* change_input_to_int32() - int32 will be used as input, can get better performance.\n",
    "* change_input_output_float32_to_float16() - half-precision will be used in computation.\n",
    "* convert_model_float32_to_float16() - decreasing model size (255MB -> 128MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the model with ONNX Runtime, we need to create an inference session for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "print(ort.get_device())\n",
    "OPTIMIZED_512 = ort.InferenceSession('./optimized_512.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    if tensor.requires_grad:\n",
    "        return tensor.detach().cpu().numpy()\n",
    "    return tensor.cpu().numpy()\n",
    "\n",
    "def prediction_onnx(model, sentence: str, max_len: int = 512):\n",
    "    encoded = tokenizer.encode_plus(sentence, add_special_tokens=True, \n",
    "                                    pad_to_max_length=True, max_length=max_len,\n",
    "                                    return_tensors=\"pt\",)\n",
    "    # compute ONNX Runtime output prediction\n",
    "    input_ids = to_numpy(encoded['input_ids'])\n",
    "    attention_mask = to_numpy(encoded['attention_mask'])\n",
    "    onnx_input = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "    logits = model.run(None, onnx_input)\n",
    "    preds = softmax(logits[0][0])\n",
    "    print(f\"Class: {['Negative' if preds.argmax() == 0 else 'Positive'][0]}, Probability: {preds.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Positive, Probability: 0.9975\n"
     ]
    }
   ],
   "source": [
    "prediction_onnx(OPTIMIZED_512, test_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
